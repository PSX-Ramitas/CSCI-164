{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries and Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 16  # Assuming you have 15 different cat breeds\n",
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish path to Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'CatBreeds\\\\Gano-Cat-Breeds-V1_1'\n",
    "if not os.path.exists(data_dir):\n",
    "    raise FileNotFoundError(f\"The directory '{data_dir}' does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDataset(Dataset):\n",
    "    def __init__(self, filenames, labels, transform=None):\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.filenames[idx]).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Assuming RGB images\n",
    "])\n",
    "\n",
    "# Data preprocessing transformation\n",
    "preprocess_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Assuming RGB images\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store file paths and labels\n",
    "all_filenames = []\n",
    "all_labels = []\n",
    "\n",
    "# Loop through each subdirectory (each breed)\n",
    "for label in os.listdir(data_dir):\n",
    "    label_dir = os.path.join(data_dir, label)\n",
    "    # Loop through each image file in the subdirectory\n",
    "    for filename in os.listdir(label_dir):\n",
    "        all_filenames.append(os.path.join(label_dir, filename))\n",
    "        all_labels.append(label)  # Append the label name (categorical) without conversion\n",
    "\n",
    "# Convert labels to numerical indices\n",
    "label_to_index = {label: idx for idx, label in enumerate(set(all_labels))}\n",
    "\n",
    "# Convert all labels to numerical indices using the dictionary\n",
    "all_labels_numeric = [label_to_index[label] for label in all_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset size: 4500\n",
      "Validation Dataset size: 1125\n"
     ]
    }
   ],
   "source": [
    "# Split indices\n",
    "train_indices, val_indices = train_test_split(np.arange(len(all_filenames)), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CatDataset(np.array(all_filenames)[train_indices], np.array(all_labels_numeric)[train_indices], transform=train_transform)\n",
    "val_dataset = CatDataset(np.array(all_filenames)[val_indices], np.array(all_labels_numeric)[val_indices], transform=preprocess_transform)\n",
    "\n",
    "# Create data loaders with samplers\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Train Dataset size:\", len(train_dataset))\n",
    "print(\"Validation Dataset size:\", len(val_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define CNN, Loss Function, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             896\n",
      "         MaxPool2d-2           [-1, 32, 32, 32]               0\n",
      "           Dropout-3           [-1, 32, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          18,496\n",
      "         MaxPool2d-5           [-1, 64, 16, 16]               0\n",
      "           Dropout-6           [-1, 64, 16, 16]               0\n",
      "            Conv2d-7          [-1, 128, 16, 16]          73,856\n",
      "         MaxPool2d-8            [-1, 128, 8, 8]               0\n",
      "           Dropout-9            [-1, 128, 8, 8]               0\n",
      "           Linear-10                  [-1, 128]       1,048,704\n",
      "           Linear-11                   [-1, 16]           2,064\n",
      "================================================================\n",
      "Total params: 1,144,016\n",
      "Trainable params: 1,144,016\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.63\n",
      "Params size (MB): 4.36\n",
      "Estimated Total Size (MB): 7.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, NUM_CLASSES)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x.to(device))))\n",
    "        #x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN().to(device)\n",
    "summary(model, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin Training and Record Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate accuracy\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Define function to calculate precision\n",
    "def calculate_precision(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    true_positives = ((predicted == 1) & (labels == 1)).sum().item()\n",
    "    false_positives = ((predicted == 1) & (labels == 0)).sum().item()\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    return precision\n",
    "\n",
    "# Define function to calculate recall\n",
    "def calculate_recall(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    true_positives = ((predicted == 1) & (labels == 1)).sum().item()\n",
    "    false_negatives = ((predicted == 0) & (labels == 1)).sum().item()\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    return recall\n",
    "\n",
    "# Define function to calculate false positives and false negatives\n",
    "def calculate_false_predictions(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    false_positives = ((predicted == 1) & (labels == 0)).sum().item()\n",
    "    false_negatives = ((predicted == 0) & (labels == 1)).sum().item()\n",
    "    return false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Train Loss: 2.6046, Train Acc: 0.1182, Val Loss: 2.4784, Val Acc: 0.1511, Train Precision: 0.5238, Train Recall: 0.4342, Val Precision: 0.4000, Val Recall: 0.5455\n",
      "Epoch 2/100: Train Loss: 2.4212, Train Acc: 0.1787, Val Loss: 2.3019, Val Acc: 0.2249, Train Precision: 0.7115, Train Recall: 0.4805, Val Precision: 0.7500, Val Recall: 0.7500\n",
      "Epoch 3/100: Train Loss: 2.2643, Train Acc: 0.2484, Val Loss: 2.2649, Val Acc: 0.2604, Train Precision: 0.8095, Train Recall: 0.6538, Val Precision: 1.0000, Val Recall: 0.0400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m false_positives_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     25\u001b[0m false_negatives_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 27\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36mCatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 11\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:916\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[0;32m    870\u001b[0m ):\n\u001b[0;32m    871\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    918\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    920\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tomas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize Arrays to keep track of metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_false_positives = []\n",
    "train_false_negatives = []\n",
    "val_false_positives = []\n",
    "val_false_negatives = []\n",
    "train_precisions = []\n",
    "val_precisions = []\n",
    "train_recalls = []\n",
    "val_recalls = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_false_positives_epoch = 0\n",
    "    train_false_negatives_epoch = 0\n",
    "    true_positives_epoch = 0\n",
    "    false_positives_epoch = 0\n",
    "    false_negatives_epoch = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        # Convert labels to torch.long\n",
    "        labels = labels.long()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        false_positives, false_negatives = calculate_false_predictions(outputs, labels)\n",
    "        train_false_positives_epoch += false_positives\n",
    "        train_false_negatives_epoch += false_negatives\n",
    "        true_positives_epoch += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "        false_positives_epoch += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "        false_negatives_epoch += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "    train_precision = true_positives_epoch / (true_positives_epoch + false_positives_epoch + 1e-10)  # to avoid division by zero\n",
    "    train_recall = true_positives_epoch / (true_positives_epoch + false_negatives_epoch + 1e-10)  # to avoid division by zero\n",
    "\n",
    "    # Append false positives and false negatives\n",
    "    train_false_positives.append(train_false_positives_epoch)\n",
    "    train_false_negatives.append(train_false_negatives_epoch)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "    val_false_positives_epoch = 0\n",
    "    val_false_negatives_epoch = 0\n",
    "    val_true_positives_epoch = 0\n",
    "    val_false_positives_epoch = 0\n",
    "    val_false_negatives_epoch = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            # Convert labels to torch.long\n",
    "            labels = labels.long()\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "            val_total += labels.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            false_positives, false_negatives = calculate_false_predictions(outputs, labels)\n",
    "            val_false_positives_epoch += false_positives\n",
    "            val_false_negatives_epoch += false_negatives\n",
    "            val_true_positives_epoch += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "            val_false_positives_epoch += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "            val_false_negatives_epoch += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "    val_precision = val_true_positives_epoch / (val_true_positives_epoch + val_false_positives_epoch + 1e-10)  # to avoid division by zero\n",
    "    val_recall = val_true_positives_epoch / (val_true_positives_epoch + val_false_negatives_epoch + 1e-10)  # to avoid division by zero\n",
    "\n",
    "    # Append false positives and false negatives\n",
    "    val_false_positives.append(val_false_positives_epoch)\n",
    "    val_false_negatives.append(val_false_negatives_epoch)\n",
    "\n",
    "    # Print and store metrics\n",
    "    print(f'Epoch {epoch + 1}/{NUM_EPOCHS}: '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, '\n",
    "          f'Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, '\n",
    "          f'Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}')\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    train_precisions.append(train_precision)\n",
    "    train_recalls.append(train_recall)\n",
    "    val_precisions.append(val_precision)\n",
    "    val_recalls.append(val_recall)\n",
    "\n",
    "print(\"Finished training\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'catModels.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_accuracies, label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation precision\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_precisions, label='Train Precision')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_precisions, label='Val Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot false positives and false negatives\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_false_positives, label='Train False Positives')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_false_negatives, label='Train False Negatives')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_false_positives, label='Val False Positives')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_false_negatives, label='Val False Negatives')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Count')\n",
    "plt.title('False Positives and False Negatives')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation recall\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_recalls, label='Train Recall')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_recalls, label='Val Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load('catModels.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_breed(image_path):\n",
    "    # Load and preprocess the test image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # Preprocess the image for the model\n",
    "    img_tensor = train_transform(img).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    output = model(img_tensor)\n",
    "    probabilities = torch.softmax(output, dim=1)\n",
    "    confidence, predicted_class = torch.max(probabilities, 1)\n",
    "    \n",
    "    # Map predicted index to breed label\n",
    "    index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "    predicted_breed = index_to_label[predicted_class.item()]\n",
    "    \n",
    "    return predicted_breed, confidence.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test image path\n",
    "test_image_path = 'test.jpg'\n",
    "\n",
    "# Predict breed of the test image with confidence level\n",
    "prediction, confidence = predict_breed(test_image_path)\n",
    "print(f\"Predicted breed: {prediction}, Confidence: {confidence * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
