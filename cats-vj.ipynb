{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries and Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import cv2  # OpenCV\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 16  # Assuming you have 15 different cat breeds\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish Path to Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'CatBreeds/Gano-Cat-Breeds-V1_1'\n",
    "preprocessed_dir = 'catbreeds-preprocessed-vj'\n",
    "if not os.path.exists(data_dir):\n",
    "    raise FileNotFoundError(f\"The directory '{data_dir}' does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Pre-Trained Haar Cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_face_cascade = cv2.CascadeClassifier('haarcascade_frontalcatface_extended.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop the Data with Viola-Jones and Haar-Like features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images_vj(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Get the total number of images to preprocess\n",
    "    total_images = sum(len(files) for _, _, files in os.walk(input_dir))\n",
    "    \n",
    "    with tqdm(total=total_images, desc='Preprocessing Images') as pbar:\n",
    "        for label in os.listdir(input_dir):\n",
    "            label_dir = os.path.join(input_dir, label)\n",
    "            output_label_dir = os.path.join(output_dir, label)\n",
    "            if not os.path.exists(output_label_dir):\n",
    "                os.makedirs(output_label_dir)\n",
    "            for filename in os.listdir(label_dir):\n",
    "                input_path = os.path.join(label_dir, filename)\n",
    "                img = cv2.imread(input_path)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                cat_faces = cat_face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3, minSize=(30, 30))\n",
    "                if len(cat_faces) > 0:\n",
    "                    x, y, w, h = cat_faces[0]\n",
    "                    face_img = img[y:y+h, x:x+w]\n",
    "                    output_path = os.path.join(output_label_dir, filename)\n",
    "                    cv2.imwrite(output_path, face_img)\n",
    "                pbar.update(1)  # Update the loading bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_images_vj(data_dir, preprocessed_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map labels to indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = {label: idx for idx, label in enumerate(os.listdir(data_dir))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the actual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessedCatDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        for label in os.listdir(root_dir):\n",
    "            label_dir = os.path.join(root_dir, label)\n",
    "            label_index = label_to_index[label]  # Convert label to index\n",
    "            for filename in os.listdir(label_dir):\n",
    "                self.image_paths.append(os.path.join(label_dir, filename))\n",
    "                self.labels.append(label_index)  # Append the label index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment Data Further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Assuming RGB images\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset = PreprocessedCatDataset(root_dir=preprocessed_dir, transform=train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = train_test_split(np.arange(len(preprocessed_dataset)), test_size=0.2, random_state=42)\n",
    "train_loader = DataLoader(preprocessed_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(preprocessed_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"Train Dataset size:\", len(train_indices))\n",
    "print(\"Validation Dataset size:\", len(val_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             896\n",
      "         MaxPool2d-2           [-1, 32, 32, 32]               0\n",
      "           Dropout-3           [-1, 32, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          18,496\n",
      "         MaxPool2d-5           [-1, 64, 16, 16]               0\n",
      "           Dropout-6           [-1, 64, 16, 16]               0\n",
      "            Conv2d-7          [-1, 128, 16, 16]          73,856\n",
      "         MaxPool2d-8            [-1, 128, 8, 8]               0\n",
      "           Dropout-9            [-1, 128, 8, 8]               0\n",
      "           Linear-10                  [-1, 128]       1,048,704\n",
      "           Linear-11                   [-1, 16]           2,064\n",
      "================================================================\n",
      "Total params: 1,144,016\n",
      "Trainable params: 1,144,016\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.63\n",
      "Params size (MB): 4.36\n",
      "Estimated Total Size (MB): 7.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, NUM_CLASSES)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "summary(model, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Visual Model of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cnn_model.png'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "# Create a dummy input tensor with the same shape as your actual input\n",
    "dummy_input = torch.randn(1, 3, 64, 64)  # (batch_size, channels, height, width)\n",
    "\n",
    "# Pass the dummy input through the model and make a visual of the computational graph\n",
    "output = model(dummy_input)\n",
    "graph = make_dot(output, params=dict(model.named_parameters()))\n",
    "graph.render(\"cnn_model\", format=\"png\", cleanup = True)  # Save the diagram as an image file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin Training and Record Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate accuracy\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Define function to calculate precision\n",
    "def calculate_precision(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    true_positives = ((predicted == 1) & (labels == 1)).sum().item()\n",
    "    false_positives = ((predicted == 1) & (labels == 0)).sum().item()\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    return precision\n",
    "\n",
    "# Define function to calculate recall\n",
    "def calculate_recall(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    true_positives = ((predicted == 1) & (labels == 1)).sum().item()\n",
    "    false_negatives = ((predicted == 0) & (labels == 1)).sum().item()\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    return recall\n",
    "\n",
    "# Define function to calculate false positives and false negatives\n",
    "def calculate_false_predictions(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    false_positives = ((predicted == 1) & (labels == 0)).sum().item()\n",
    "    false_negatives = ((predicted == 0) & (labels == 1)).sum().item()\n",
    "    return false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Arrays to keep track of metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_false_positives = []\n",
    "train_false_negatives = []\n",
    "val_false_positives = []\n",
    "val_false_negatives = []\n",
    "train_precisions = []\n",
    "val_precisions = []\n",
    "train_recalls = []\n",
    "val_recalls = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_false_positives_epoch = 0\n",
    "    train_false_negatives_epoch = 0\n",
    "    true_positives_epoch = 0\n",
    "    false_positives_epoch = 0\n",
    "    false_negatives_epoch = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        false_positives, false_negatives = calculate_false_predictions(outputs, labels)\n",
    "        train_false_positives_epoch += false_positives\n",
    "        train_false_negatives_epoch += false_negatives\n",
    "        true_positives_epoch += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "        false_positives_epoch += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "        false_negatives_epoch += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "    train_precision = true_positives_epoch / (true_positives_epoch + false_positives_epoch + 1e-10)  # to avoid division by zero\n",
    "    train_recall = true_positives_epoch / (true_positives_epoch + false_negatives_epoch + 1e-10)  # to avoid division by zero\n",
    "\n",
    "    # Append false positives and false negatives\n",
    "    train_false_positives.append(train_false_positives_epoch)\n",
    "    train_false_negatives.append(train_false_negatives_epoch)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "    val_false_positives_epoch = 0\n",
    "    val_false_negatives_epoch = 0\n",
    "    val_true_positives_epoch = 0\n",
    "    val_false_positives_epoch = 0\n",
    "    val_false_negatives_epoch = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "            val_total += labels.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            false_positives, false_negatives = calculate_false_predictions(outputs, labels)\n",
    "            val_false_positives_epoch += false_positives\n",
    "            val_false_negatives_epoch += false_negatives\n",
    "            val_true_positives_epoch += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "            val_false_positives_epoch += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "            val_false_negatives_epoch += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "    val_precision = val_true_positives_epoch / (val_true_positives_epoch + val_false_positives_epoch + 1e-10)  # to avoid division by zero\n",
    "    val_recall = val_true_positives_epoch / (val_true_positives_epoch + val_false_negatives_epoch + 1e-10)  # to avoid division by zero\n",
    "\n",
    "    # Append false positives and false negatives\n",
    "    val_false_positives.append(val_false_positives_epoch)\n",
    "    val_false_negatives.append(val_false_negatives_epoch)\n",
    "\n",
    "    # Print and store metrics\n",
    "    print(f'Epoch {epoch + 1}/{NUM_EPOCHS}: '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, '\n",
    "          f'Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, '\n",
    "          f'Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}')\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    train_precisions.append(train_precision)\n",
    "    train_recalls.append(train_recall)\n",
    "    val_precisions.append(val_precision)\n",
    "    val_recalls.append(val_recall)\n",
    "\n",
    "print(\"Finished training\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'catModelsVJ.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_accuracies, label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation precision\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_precisions, label='Train Precision')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_precisions, label='Val Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot false positives and false negatives\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_false_positives, label='Train False Positives')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_false_negatives, label='Train False Negatives')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_false_positives, label='Val False Positives')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_false_negatives, label='Val False Negatives')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Count')\n",
    "plt.title('False Positives and False Negatives')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation recall\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_recalls, label='Train Recall')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_recalls, label='Val Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Model for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load('catModelsVJ.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually test on input test.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_breed(image_path):\n",
    "    # Load and preprocess the test image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_copy = img.copy()  # Create a copy of the original image\n",
    "    \n",
    "    # Convert image to grayscale for face detection\n",
    "    gray = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Detect cat faces\n",
    "    cat_faces = cat_face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3, minSize=(30, 30))\n",
    "    \n",
    "    # If faces are detected, draw rectangles around them and display the images\n",
    "    if len(cat_faces) > 0:\n",
    "        for (x, y, w, h) in cat_faces:\n",
    "            cv2.rectangle(np.array(img_copy), (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        # Preprocess the image for the model\n",
    "        img_tensor = train_transform(img_copy).unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        output = model(img_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        confidence, predicted_class = torch.max(probabilities, 1)\n",
    "    \n",
    "        # Map predicted index to breed label\n",
    "        index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "        predicted_breed = index_to_label[predicted_class.item()]\n",
    "    else:\n",
    "        print(\"No cat faces detected. Using original image instead.\")\n",
    "        # Preprocess the image for the model\n",
    "        img_tensor = train_transform(img).unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        output = model(img_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        confidence, predicted_class = torch.max(probabilities, 1)\n",
    "    \n",
    "        # Map predicted index to breed label\n",
    "        index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "        predicted_breed = index_to_label[predicted_class.item()]\n",
    "    \n",
    "    return predicted_breed, confidence.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test image path\n",
    "test_image = 'test.jpg'\n",
    "\n",
    "# Predict breed of the test image with confidence level\n",
    "prediction, confidence = predict_breed(test_image)\n",
    "print(f\"Predicted breed: {prediction}, Confidence: {confidence * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
